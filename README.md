[> Check the live project <](m1-panorama.vercel.app)

# M2 Panorama Stitching WIP

This project is a little proof of concept to use a smartphone to take images along with the smartphone orientation to then stitch the camera images together and calculate the camera's field of view.
The code in this repository is far from finished and only to be understood as an experimental Proof of Concept.

The project is using the following technologies:
-  [OpenCV.js](https://docs.opencv.org/3.4/d5/d10/tutorial_js_root.html) for image stitching and field of view calculation
-  [three.js](https://threejs.org/) for creating the AR part for image taking
-  [React](https://react.dev/) as the frontend framework


Inspired by the work of latsic's [imgalign](https://github.com/latsic/imgalign).

## Available Scripts

In the project directory, you can:

run `yarn start`

Runs the app in the development mode.\
Open [http://localhost:3000](http://localhost:3000) to view it in your browser.
